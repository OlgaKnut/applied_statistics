{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we compleated 4 tasks related to applied statistics using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries necessary for tasks  \n",
    "\n",
    "# Mathematical functions from the standard library.\n",
    "# https://docs.python.org/3/library/math.html\n",
    "import math\n",
    "\n",
    "# Permutations and combinations.\n",
    "# https://docs.python.org/3/library/itertools.html\n",
    "import itertools\n",
    "\n",
    "# Random selections.\n",
    "# https://docs.python.org/3/library/random.html\n",
    "import random\n",
    "\n",
    "# Numerical structures and operations.\n",
    "# https://numpy.org/doc/stable/reference/index.html#reference\n",
    "import numpy as np\n",
    "\n",
    "# Plotting.\n",
    "# https://matplotlib.org/stable/contents.html\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Statistical tests\n",
    "# https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Statistical data visualization.\n",
    "#https://seaborn.pydata.org/#seaborn-statistical-data-visualization\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:Permutations and Combinations   \n",
    "\n",
    " **Suppose we alter the Lady Tasting Tea experiment to involve twelve cups of tea. Six have the milk in first and the other six having tea in first.   \n",
    " A person claims they have the special power of being able to tell whether the tea or the milk went into a cup first upon tasting it.   \n",
    " You agree to accept their claim if they can tell which of the six cups in your experiment had the milk in first.  \n",
    " Calculate, using Python, the probability that they select the correct six cups.   \n",
    " Here you should assume that they have no special powers in figuring it out, that they are just guessing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cups of tea in total.\n",
    "no_cups = 12\n",
    "# Number of cups of tea with milk in first.\n",
    "no_cups_milk_first = 6\n",
    "# Number of ways of selecting 6 cups from 12.\n",
    "ways = math.comb(no_cups, no_cups_milk_first)\n",
    "# Show.\n",
    "ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of 924 possible ways of selecting 6 cups out of 12 only one is all 6 \"milk_first\"\n",
    "# The probability that they (randomly) selects the 6 correct cups.\n",
    "\n",
    "1 / 924"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As we can see the probability of randoly selecting 6 correct cups is very low.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose, now, you are willing to accept one error. Once they select the six cups they think had the milk in first, you will give them the benefit of the doubt should they have selected at least five of the correct cups. Calculate the probability, assuming they have no special powers, that the person makes at most one error.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cups of tea in total.\n",
    "n = 12\n",
    "# Number of cups of tea with milk in first.\n",
    "k = 6\n",
    "# 12 factorial.\n",
    "math.factorial(n)\n",
    "# 6 factorial.\n",
    "math.factorial(n - k)\n",
    "# No of ways of selecting k objects from n without replacement and without order.\n",
    "math.factorial(n) // (math.factorial(k) * math.factorial(n - k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cup labels.\n",
    "labels = list(range(no_cups))\n",
    "\n",
    "# Show.\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the different ways of selecting no_cups_milk_first out of no_cups cups of tea.\n",
    "combs = list(itertools.combinations(labels, no_cups_milk_first))\n",
    "\n",
    "# Show.\n",
    "#combs\n",
    "\n",
    "# Number of combinations.\n",
    "len(combs)\n",
    "\n",
    "# Select four cups at random to put milk in first.\n",
    "# https://docs.python.org/3/library/random.html#random.sample\n",
    "labels_milk = random.sample(labels, 6)\n",
    "\n",
    "# Sort, inplace.\n",
    "labels_milk.sort()\n",
    "\n",
    "# Show.\n",
    "labels_milk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn labels_milk into a set.\n",
    "# Uses: https://docs.python.org/3/tutorial/datastructures.html#sets\n",
    "set(labels_milk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overlap between each element of combs and labels_milk.\n",
    "\n",
    "no_overlaps = []\n",
    "\n",
    "for comb in combs:\n",
    "  # Turn comb into a set.\n",
    "  s1 = set(comb)\n",
    "  # Turn labels_milk into a set.\n",
    "  s2 = set(labels_milk)\n",
    "  # Figure out where they overlap.\n",
    "  overlap = s1.intersection(s2)\n",
    "  # Show the combination and the overlap.\n",
    "  #print(comb, overlap, len(overlap))\n",
    "  # Append overlap to no_overlaps.\n",
    "  no_overlaps.append(len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each overlap occurs.\n",
    "counts = np.unique(no_overlaps, return_counts=True)\n",
    "\n",
    "# Show.\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure.\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# Bar chart.\n",
    "ax.bar(counts[0], counts[1]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability that they (randomly) selects at least 5 correct cups.\n",
    "(36 + 1) / 924"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we compare probability of correct selection of 6 cups (0.0010822510822510823)\n",
    "with one error expected (0.04004329004329004) we can see that it is noticeably higher for one error, but still quite low.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Would you accept two errors? Explain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability that they (randomly) selects at least 4 correct cups.\n",
    "(225 + 36 + 1) / 924"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Probability of selecting all 6 correct cups: 0.0010822510822510823 (≈ 0.11%).\n",
    "- Probability of selecting at most one error (5 or 6 correct): 0.04004329004329004 (≈ 4.00%).\n",
    "- Probability of selecting at most two errors (4, 5 or 6 correct): 0.28354978354978355 (≈ 28.00%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion:  \n",
    "\n",
    " If we accept at most one error (5 or 6 correct cups), the person has about a 4% chance of succeeding by random guessing. If you accept two errors (4 and more correct cups), the probability jumps to 28%. This makes it much more likely that the person could sicceed by random guessing. We will not accept two errors if we what to establish ability to tell the diffrence between \"milk first\" and \"tea first\" cups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: numpy's Normal Distribution ####\n",
    "**Assess whether numpy.random.normal() properly generates normal values. To begin, generate a sample of one hundred thousand values using the function with mean 10.0 and standard deviation 3.0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a sample of one hundred thousand values \n",
    "# using the function with mean 10.0 and standard deviation 3.0\n",
    "\n",
    "#setting parametrs in numpy documentation \n",
    "# mean - loc, \n",
    "# standard deviation - scale, \n",
    "mean = 10.0\n",
    "std_dev = 3.0\n",
    "sample_size = (100000)\n",
    "#genereting the sample\n",
    "\n",
    "sample = np.random.normal(mean, std_dev, sample_size)\n",
    "\n",
    "#print first 10 values\n",
    "print(sample[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the scipy.stats.shapiro() function to test whether your sample came from a normal distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the scipy.stats.shapiro() function \n",
    "# to test whether your sample came from a normal distribution. \n",
    "stats.shapiro(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain the results and output.**  \n",
    "\n",
    "We received two outputs:\n",
    "\n",
    "- statistic- A measure of how closely your sample resembles a normal distribution.  \n",
    "The closer this statistic is to 1, the more normal the data.\n",
    "- p-value: This indicates whether the sample's deviation from normality is statistically significant.  \n",
    "If p-value > 0.05: Fail to reject the null hypothesis. This suggests that there’s no strong evidence against normality, so it’s reasonable to assume the data comes from a normal distribution.\n",
    "If p-value ≤ 0.05: Reject the null hypothesis. This means there’s evidence that the sample is not normally distributed.*\n",
    "https://en.wikipedia.org/wiki/Shapiro-Wilk_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a histogram of your values and plot the corresponding normal distribution probability density function on top of it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a histogram of your values \n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sample,bins=51, edgecolor='black', density=True)\n",
    "\n",
    "# and plot the corresponding normal distribution probability density function on top of \n",
    "x = np.linspace(mean - 4 * std_dev, mean + 4 * std_dev, 1000)\n",
    "pdf = stats.norm.pdf(x, mean, std_dev)\n",
    "plt.plot(x, pdf, 'r', linewidth=2, label=\"Normal Distribution PDF\")\n",
    "# Add titles and labels\n",
    "plt.title(\"Histogram of Sample Data with Normal Distribution PDF\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We visualized the data using a histogram overlaid with the corresponding probability density function (PDF) of a normal distribution with the same mean and standard deviation. The histogram closely matched the theoretical PDF, further supporting the correctness of numpy.random.normal() in generating normal values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion:  \n",
    "Both statistical testing and visual inspection confirm that numpy.random.normal() produces data that aligns well with the properties of a normal distribution under the specified parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: t-Test Calculation ####\n",
    "**Consider the following dataset containing resting heart rates for patients before and after embarking on a two-week exercise program.**\n",
    "\n",
    "| Patient ID | 0  | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  |\n",
    "|------------|----|----|----|----|----|----|----|----|----|----|\n",
    "| Before     | 63 | 68 | 70 | 64 | 74 | 67 | 70 | 57 | 66 | 65 |\n",
    "| After      | 64 | 64 | 68 | 64 | 73 | 70 | 72 | 54 | 61 | 63 |\n",
    "\n",
    "**Calculate the t-statistic based on this data set, using Python. Compare it to the value given by scipy.stats. Explain your work and list any sources used.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the data\n",
    "before = np.array([63, 68, 70, 64, 74, 67, 70, 57, 66, 65])\n",
    "after = np.array([64, 64, 68, 64, 73, 70, 72, 54, 61, 63])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing data\n",
    "To gain some insights into the data, we visualized it using multiple techniques.  \n",
    "A histogram is plotted to observe the distribution of the differences in heart rates, revealing the spread and central tendency of the data.  \n",
    "A scatter plot is generated to show the relationship between \"before\" and \"after\" heart rates for each patient, offering a visual representation of any consistent trends or changes.  \n",
    "A box plot is used to identify potential outliers and compare the central tendency and spread before and after the exercise program.  \n",
    "These visualizations helped in understanding the data characteristics and patterns beyond numerical statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty data frame.\n",
    "fig, ax = plt.subplots()\n",
    "# Create histogram.\n",
    "ax.hist(before, bins = 10, color='blue', alpha=0.5, label='Before')\n",
    "ax.hist(after, bins = 10, color='green', alpha=0.5, label='After')\n",
    "ax.set_title(\"Histogram of Heart Rates\")\n",
    "ax.set_xlabel(\"Heart Rate (BPM)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.legend()\n",
    "\n",
    "#Fix x-axis ticks by setting a range of values\n",
    "min_tick = min(before.min(), after.min()) - 1\n",
    "max_tick = max(before.max(), after.max()) + 1\n",
    "ax.set_xticks(range(min_tick, max_tick + 1, 1))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "# Create a strip plot.\n",
    "sns.stripplot(data=[before, after], ax=ax[0], palette=[\"blue\", \"green\"])\n",
    "ax[0].set_xticks([0,1])\n",
    "ax[0].set_xticklabels([\"Before\", \"After\"])\n",
    "ax[0].set_title(\"Strip Plot of Heart Rates\")\n",
    "\n",
    "# Create a box plot for \"before\" and \"after\" data\n",
    "sns.boxplot(data=[before, after], ax=ax[1], palette=[\"blue\", \"green\"])\n",
    "ax[1].set_xticks([0, 1])\n",
    "ax[1].set_xticklabels([\"Before\", \"After\"])\n",
    "ax[1].set_title(\"Box Plot of Heart Rates\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we visually compare \"before\" and \"after\" datasets we can decide that heart rate is lower after two-week exercise program*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the t-statistic based on this data set, using Python.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate the differences\n",
    "differences = after - before\n",
    "\n",
    "# Step 3: Calculate the mean and standard deviation of the differences\n",
    "mean_diff = np.mean(differences)\n",
    "std_diff = np.std(differences, ddof=1)  # ddof=1 for sample standard deviation\n",
    "n = len(differences)\n",
    "\n",
    "# Step 4: Calculate the t-statistic\n",
    "t_statistic_python = mean_diff / (std_diff / np.sqrt(n))\n",
    "\n",
    "# Output results\n",
    "t_statistic_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the t-statistic by scipy.stats.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Verify with scipy.stats\n",
    "t_statistic_scipy, p_value_scipy = stats.ttest_rel(after, before)\n",
    "\n",
    "# Output results\n",
    "t_statistic_scipy, p_value_scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion:  \n",
    "\n",
    "Manual Calculation: We calculated the mean and standard deviation of the differences in resting heart rates before and after the program, used these values to find the t-statistic, and confirmed it was \n",
    "− 1.337\n",
    "Scipy Calculationn: scipy.stats.ttest_rel gave the same t-statistic of \n",
    "− 1.337 and a p-value of 0.214\n",
    "\n",
    "indicating no statistically significant change in heart rate at a typical \n",
    "0.05 significance level.\n",
    "\n",
    "This verification method shows consistency between manual calculations and scipy’s implementation.  \n",
    "If we visually compare the \"before\" and \"after\" datasets, there is a slight indication that heart rates appear lower after the two-week exercise program. While this trend is observable, it is not strong enough to be statistically significant based on the t-test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: ANOVA ####\n",
    "**In this test we will estimate the probability of committing a type II error in specific circumstances. To begin, create a variable called no_type_ii and set it to 0.  \n",
    "Now use a loop to perform the following test 10,000 times.  \n",
    "Use numpy.random.normal to generate three samples with 100 values each. Give each a standard deviation of 0.1. Give the first sample a mean of 4.9, the second a mean of 5.0, and the third a mean of 5.1.  \n",
    "Perform one-way anova on the three samples and add 1 to no_type_ii whenever a type II error occurs.  \n",
    "Summarize and explain your results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a variable called no_type_ii and set it to 0.\n",
    "no_type_ii = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for the test\n",
    "num_tests = 10000  # Number of iterations\n",
    "num_values = 100    # Number of values in each sample\n",
    "std_dev = 0.1       # Standard deviation for each sample\n",
    "means = [4.9, 5.0, 5.1]\n",
    "# Perform the test 10,000 times\n",
    "samples = []\n",
    "\n",
    "for _ in range(num_tests):\n",
    "    # Generate three samples with the specified means and standard deviation\n",
    "    sample1 = np.random.normal(means[0], std_dev, num_values)\n",
    "    sample2 = np.random.normal(means[1], std_dev, num_values)\n",
    "    sample3 = np.random.normal(means[2], std_dev, num_values)\n",
    "    \n",
    "    # Perform one-way ANOVA\n",
    "    f_stat, p_value = stats.f_oneway(sample1, sample2, sample3)\n",
    "    \n",
    "    # If p-value is greater than 0.05, it means we failed to reject the null hypothesis (Type II error)\n",
    "    if p_value > 0.05:\n",
    "        no_type_ii += 1\n",
    "\n",
    "# Display the number of Type II errors\n",
    "print(f\"Number of Type II errors: {no_type_ii}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion:  \n",
    "- The absence of type II errors in this simulation suggests that the ANOVA test had sufficient statistical power to detect even the subtle differences between the sample means, given the low variability (standard deviation of 0.1) and relatively large sample size (100 values per sample).\n",
    "- The result emphasizes the robustness of ANOVA when applied to datasets with low variability and well-distributed sample sizes.\n",
    "- The combination of the effect size, low standard deviation, and moderate sample size made the differences between the means statistically detectable in every iteration.\n",
    "- This test demonstrated that under the given conditions, the probability of committing a type II error was effectively 0.0, showcasing the high sensitivity of ANOVA in detecting differences in means when variability is minimal and sample sizes are sufficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
